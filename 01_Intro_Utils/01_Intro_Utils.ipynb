{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercícios - 20210718 - Leonardo de Lellis Rossi",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leolellisr/deep_learning_projects/blob/main/01_Intro_Utils/01_Intro_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe"
      },
      "source": [
        "print('Meu nome é: Leonardo de Lellis Rossi - RA 261900')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "from collections import Counter\n",
        "def top_k(L, k):\n",
        "    # Escreva aqui o código\n",
        "    \n",
        "    if(debug): print(f\"Most {k} commom items and freq: {Counter(L).most_common(k)}\")\n",
        "\n",
        "    # using collections.Counter(list).most_common(k) to get the k most common items on a list and convert it to dict\n",
        "    \n",
        "    return dict(Counter(L).most_common(k))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627aab63-02d2-453a-fcb7-33109c100478"
      },
      "source": [
        "debug = False\n",
        "\n",
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')\n",
        "\n",
        "#E.g.:\n",
        "if(debug):\n",
        "  L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']\n",
        "  dictTopL = top_k(L,2)\n",
        "  print(f\"type of dictTopL: {type(dictTopL)}\")\n",
        "  print(f\"dictTopL: {dictTopL}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca1f640-d0b6-472c-8eb5-d9df996a80ce"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 592 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "import re\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "    # escreva o código aqui.\n",
        "\n",
        "    lower_case = text.lower()\n",
        "    if(debug): print(f\"lower_case string: {lower_case.split()}\")\n",
        "\n",
        "    # Getting list of words and pontuaction with re.findall\n",
        "    re_split = re.findall(r\"[\\w']+|[.,!?;]\",lower_case)\n",
        "    if(debug): print(f\"re.findall: {re_split}\")\n",
        "\n",
        "    # Encoding the array with vocabulary dict\n",
        "\n",
        "    # How optimize / change for & if/else to get unknown keys?  \n",
        "    \n",
        "    decode_array = []\n",
        "    for k in re_split:\n",
        "      if k in vocabulary: \n",
        "        decode_array.append(vocabulary[k])\n",
        "      else:\n",
        "        decode_array.append(-1)\n",
        "    \n",
        "    if(debug): print(f\"number_word: {decode_array}\")\n",
        "    return decode_array\n",
        "\n",
        "if(debug): \n",
        "  V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "  D = 'Eu gosto de comer pizza.'\n",
        "  print(tokens_to_ids(D, V))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81238935-628b-4597-935a-97e78f5c3de1"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0251c367-a0c8-49c4-f11d-54cc14216524"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.48 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "import random\n",
        "from linecache import getline\n",
        "debug = False\n",
        "def sample(path: str, k: int):\n",
        "    # Escreva o seu código aqui.\n",
        "\n",
        "  with open(path) as f:\n",
        "    if(debug): print(f\"num lines: {len(f)}\")\n",
        "    n_lines = sum(1 for line in f)\n",
        "    # random integer list with k items and [0,total_size]\n",
        "    res = [random.randrange(0, n_lines, 1) for i in range(k)]\n",
        "    if(debug): print(f\"res: {res}\")\n",
        "  f.close()\n",
        "\n",
        "  return [getline(path, line).rstrip() for line in res]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5a1916-1fb4-4ca9-cda9-8102260c9456"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 26', 'line 66', 'line 94', 'line 34', 'line 43', 'line 72', 'line 31', 'line 8', 'line 53', 'line 88']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1395d77-e568-486d-c58e-4b1fb9055aea"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 125 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "\n",
        "Seja **Α ∈ ℜ$^{m \\times n}$** e **B ∈ ℜ$^{n \\times p}$**, o produto **AB** tem dimensão **${m \\times p}$** e cada elemento **dᵢⱼ**, produto da linha **i** de **A** pela coluna **j** de **B**, pode ser expresso por:\n",
        "\n",
        "**dᵢⱼ = ${\\sum_{k=1}^{n}}$ aᵢₖ * bₖⱼ** \n",
        "\n",
        "**dᵢⱼ = aᵢ$_1$ * b$_1$ⱼ + aᵢ$_2$ * b$_2$ⱼ + ... + aᵢₙ * bₙⱼ** \n",
        "\n",
        "Para cada dᵢⱼ (produto entre linha de A e coluna de B)  são realizadas **n** multiplicações (cada produto aᵢₖ por bⱼₖ) e **n-1** somas.\n",
        "\n",
        " Como temos **m** linhas em A e **p** colunas em B, a matriz resultante possui dimensões **m x p**: \n",
        "\n",
        "- número de somas: **m** * **p** * **(n - 1)**\n",
        "- número de multiplicações: **m** * **p** * **n**\n",
        "\n",
        "Logo, o custo total é:  **m** * **p** * **(2n - 1)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe9da16-78cd-4e1c-965a-50125c2039f6"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42262f72-89c6-4513-f01c-a1e73b81ceeb"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "\n",
        "# Getting mean with numpy.mean in axis 1\n",
        "row_means = A.mean(axis=1)\n",
        "print(row_means)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.5  8.5 14.5 20.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb3ea53-337f-40dc-cfa7-8c03baec266c"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "debug = False\n",
        "def norm(a_ij, a_min, a_max):\n",
        "  if(debug):\n",
        "    print(f\"a_ij: {a_ij}\")\n",
        "    print(f\"a_min: {a_min}\")\n",
        "    print(f\"a_max: {a_max}\")\n",
        "  return (a_ij-a_min)/(a_max-a_min)\n",
        "\n",
        "norm_A = norm(A,A.min(), A.max())\n",
        "print(norm_A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54b0ef6-d379-4bd9-ce12-3f317fa87381"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "\n",
        "debug = False\n",
        "if(debug): print(np.transpose(A))\n",
        "norm_col_A = [norm(col, col.min(), col.max()) for col in A.T]\n",
        "print(np.asmatrix(norm_col_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.33333333 0.66666667 1.        ]\n",
            " [0.         0.33333333 0.66666667 1.        ]\n",
            " [0.         0.33333333 0.66666667 1.        ]\n",
            " [0.         0.33333333 0.66666667 1.        ]\n",
            " [0.         0.33333333 0.66666667 1.        ]\n",
            " [0.         0.33333333 0.66666667 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0948e652-0223-4637-b9f5-3e0107452f29"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "norm_row_A = [norm(row, row.min(), row.max()) for row in A]\n",
        "print(np.asmatrix(norm_row_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    # Escreva sua solução aqui.\n",
        "    # softmax with - max avoids overflow. <https://www.deeplearningbook.org/contents/numerical.html>\n",
        "    norm_row_A = [np.exp(row - row.max())/(np.exp(row - row.max()).sum()) for row in A]\n",
        "\n",
        "    if(debug): print(f\"norm_row: {np.asmatrix(norm_row_A)}\")\n",
        "    \n",
        "    return np.asmatrix(norm_row_A)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78db78bb-0f53-4bbe-caf2-dc1782e27718"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.        , 1.        ],\n",
              "        [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4f3c9a-a56e-462b-c942-77744ea9a40d"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa21f17-42a4-44fd-ca36-baf5fdce266b"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 630 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2548b34-cc3b-4b69-b0d0-c320435c134b"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "    # Escreva seu código aqui.\n",
        "    return np.eye(n_classes)[y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84751c0-4111-40df-d8d2-117a3b2894e5"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 7 3 1 7 6 4 3 7]\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "# Escreva seu código aqui.\n",
        "\n",
        "#  standard score (z-score): number of standard deviations by which the value of a raw score\n",
        "# is above or below the mean value of what is being observed or measured \n",
        "# <https://en.wikipedia.org/wiki/Standard_score>\n",
        "# Computing a z-score requires knowing the mean and standard deviation of the complete population to which a data point belongs\n",
        "# Z = X (array) - mean  / std\n",
        "# X = Z * std + mean\n",
        "class Normalizer:\n",
        "    def __init__(self, array_b):\n",
        "        self.b = array_b \n",
        "        self.b_mean = np.array(array_b).mean()\n",
        "        self.b_std = np.array(array_b).std()\n",
        "\n",
        "    def __call__(self, array_a):\n",
        "        array_a=np.array(array_a) \n",
        "\n",
        "        # Getting Z\n",
        "        zscore = (array_a-array_a.mean())/array_a.std()\n",
        "        return  self.b_mean+zscore*self.b_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d63451-dec2-4095-cd4f-8e18565c4566"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cede1f5f-abcd-483d-f090-2fba080b1c78"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161d45fb-0e06-4a60-dd6e-7d68e113d9a7"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32130615-8af4-4ed1-e00e-5e17a7673ec3"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d82cea-89b1-43db-8b2f-1d9ee9d27d1d"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bf1314-0d74-4727-dd27-419f022f7066"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bd299d-11b2-4e65-a224-37ed29462ba8"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714cafd7-33ea-4529-bd1d-fdf2c9e65430"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de9ed99-0c2b-4229-e07b-72c186aa24b0"
      },
      "source": [
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    y_i = x* w\n",
        "    e_i = y_i - y\n",
        "    e2i = e_i.pow(2) \n",
        "    return e2i.sum()\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "d_w = 0.0001\n",
        "grad = (J_func(w+d_w, x,y) - J_func(w-d_w, x,y))/(2*d_w)\n",
        "print('grad=', grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-27.9999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9d96060-8323-4d39-f1ca-e6c5d851fd5a"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "d_w = 0.0001\n",
        "plot_array = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    grad = (J_func(w+d_w, x,y) - J_func(w-d_w, x,y))/(2*d_w)\n",
        "    print('grad =',grad)\n",
        "    w = (w - learning_rate*grad)\n",
        "    print('w =', w)\n",
        "    plot_array.append(J)\n",
        "# Plote aqui a loss pela iteração\n",
        "plt.xlabel(\"i (iteration)\") \n",
        "plt.ylabel(\"J (loss)\") \n",
        "plt.plot(range(iteracoes),plot_array) \n",
        "plt.show()\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-27.9999)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1607)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5137)\n",
            "w = tensor([1.6267])\n",
            "i = 3\n",
            "J= tensor(1.9505)\n",
            "grad = tensor(-10.4505)\n",
            "w = tensor([1.7312])\n",
            "i = 4\n",
            "J= tensor(1.0112)\n",
            "grad = tensor(-7.5281)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor(-5.4196)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor(-3.9014)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1407)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0729)\n",
            "grad = tensor(-2.0218)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor(-1.4555)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0472)\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7540)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5432)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3910)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2814)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2027)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1458)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1051)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0756)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2911e-05)\n",
            "grad = tensor(-0.0544)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8aa573-666b-4b5f-afcc-91d1b601f0a8"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "plot_array = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "\n",
        "    J = J_func(w, x, y)\n",
        "    J.backward()\n",
        "    print('J=', J)\n",
        "    \n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "    w = (w - learning_rate*grad)\n",
        "    w.retain_grad()\n",
        "    print('w =', w)\n",
        "\n",
        "    plot_array.append(J.detach().numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plote aqui a loss pela iteração\n",
        "plt.xlabel(\"i (iteration)\") \n",
        "plt.ylabel(\"J (loss / backward)\") \n",
        "plt.plot(range(iteracoes),plot_array) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WXm3Xua1HhVm",
        "outputId": "ad510e12-f14f-4c23-b600-bc2dfa179b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5X3v8c9vNNpsyZYXWTZekAHJxhEEjAqELTEQsAlhyW0TKCGQ5IYuoUn6appmaZab3CxNmqZcGpK4QKApoWlYGifB7FsIYLANxvsC2OBVwsa2bKz9d/84R2YsNPJY0szRzPm+X695zdnmPD8fj37nzHOe8zzm7oiISHwkog5ARERyS4lfRCRmlPhFRGJGiV9EJGaU+EVEYiYZdQCZGD9+vNfW1kYdhohIXlmyZMkb7l7de3leJP7a2loWL14cdRgiInnFzDb1tVxVPSIiMaPELyISM0r8IiIxo8QvIhIzSvwiIjGTtcRvZreaWZOZrehj3d+ZmZvZ+GyVLyIifcvmFf9twNzeC81sKnAB8FoWyxYRkTSylvjd/UlgVx+rfgR8Ach6f9CPrtnBTY9vyHYxIiJ5Jad1/GZ2KbDF3ZdlsO11ZrbYzBY3NzcPqLynN+zkhofX09WtMQdERHrkLPGb2Qjgy8DXMtne3ee7e6O7N1ZXv+OJ44zU11TS1tnN67veGtDnRUQKUS6v+I8FpgPLzGwjMAVYamYTs1VgXU0FAOt2tGSrCBGRvJOzxO/uy919grvXunstsBmY7e7bs1VmXU0lAOub9mWrCBGRvJPN5px3As8AM8xss5l9MltlpVNRmmRyVTlrt+uKX0SkR9Z653T3Kw+zvjZbZaeqq6lQVY+ISIqCf3K3vqaSV5r309nVHXUoIiLDQsEn/roJFbR3dbNJLXtERIAYJP76nhu8qu4REQFikPiPm9DTpFMte0REIAaJf2RpkiljynWDV0QkVPCJH4LqnvW64hcRAWKU+F95Yx8datkjIhKXxF9BR5ezaef+qEMREYlcTBJ/0LJHN3hFRGKS+I+trsBMnbWJiEBMEn95SRHTxo7QDV4REWKS+AHqJlTqil9EhBgl/vqaCl59Yz/tnWrZIyLxFqPEX0lnt/PqG2rZIyLxFpvEr9G4REQCsUn8x1ZXkDB11iYiEpvEX1ZcxNHjRqotv4jEXmwSPwR9869r0hW/iMRbrBJ/fU0lm3a+RVtnV9ShiIhEJpuDrd9qZk1mtiJl2Q/MbI2ZvWRm95pZVbbK70v9xEq6up1XmtWyR0TiK5tX/LcBc3stewhocPcTgXXAl7JY/jvUq2WPiEj2Er+7Pwns6rXsQXfvDGefBaZkq/y+TB8/kqKEqesGEYm1KOv4PwEsTLfSzK4zs8Vmtri5uXlICixNFlE7boSu+EUk1iJJ/Gb2FaATuCPdNu4+390b3b2xurp6yMqur6lkfZOu+EUkvnKe+M3sWuBi4Cp391yXX1dTyaad+2ntUMseEYmnnCZ+M5sLfAG4xN3fymXZPeprKuh2eLlZV/0iEk/ZbM55J/AMMMPMNpvZJ4F/AyqBh8zsRTP7abbKT+ft0bhUzy8i8ZTM1o7d/co+Ft+SrfIyVTtuJMmEqesGEYmtWD25C1CSTDB9/Eh11iYisRW7xA9BdY+u+EUkrmKZ+OtqKnj9zbc40K6WPSISP7FM/DNqKnGHDWrPLyIxFMvEX6eWPSISY7FM/LXjRlBSlFDf/CISS7FM/MmiBMdUj1RnbSISS7FM/BBU96iqR0TiKLaJv35CBZvfPMD+ts7DbywiUkBim/h7bvCqZY+IxE1sE79G4xKRuIpt4j963EhKkgn1zS8isRPbxF+UMI6trmDtdl3xi0i8xDbxQ1Ddo87aRCRuYp74K9m6p5WW1o6oQxERyZlYJ/66CcENXtXzi0icxDrxz5gYNOlUdY+IxEmsE//UMSMoK06ob34RiZVYJ/5EwjhuQoXa8otIrMQ68QPUT6hUZ20iEitZS/xmdquZNZnZipRlY83sITNbH76PyVb5maqrqWT73lb2HFDLHhGJh4wSv5mNMbN3mdkxZpbpyeI2YG6vZV8EHnH3OuCRcD5SPV03bFDf/CISE2mTuJmNNrMvm9ly4FngZ8B/A5vM7NdmNqe/Hbv7k8CuXosvBW4Pp28HLhtw5EOk/uBoXKruEZF4SPaz7i7gP4Cz3X136gozOwW42syOcfdbjqC8GnffFk5vB2rSbWhm1wHXAUybNu0Iijgyk6vKKS8u0g1eEYmNtInf3d/fz7olwJLBFOzubmbez/r5wHyAxsbGtNsNViJh1NVU6AaviMRG2sRvZrP7+6C7Lx1AeTvMbJK7bzOzSUDTAPYx5OomVPKH9c1RhyEikhP9VfX8MHwvAxqBZYABJwKLgfcMoLwFwDXA98L33wxgH0OuvqaCu5duZvdb7VSNKIk6HBGRrEp7c9fd57j7HGAbMNvdG939FOBkYMvhdmxmdwLPADPMbLOZfZIg4b/fzNYD54fzkdMNXhGJk/6u+HvMcPflPTPuvsLMjj/ch9z9yjSrzss0uFypn9iT+Fs4dfrYiKMREcmuTBL/cjO7GfjPcP4q4KXshZR7R40uo6I0qc7aRCQWMkn81wJ/BXw2nH8S+Em2AoqCWU+fParqEZHC12/iN7MiYGFY1/+j3IQUjfqaCh5dMywaGYmIZFW/3S+4exfQbWajcxRPZOprKnljXzu79rdHHYqISFZlUtWzj6Ce/yFgf89Cd/9M1qKKQF3N2zd4Tz9mXMTRiIhkTyaJ/57wVdB6Omtbr8QvIgXusInf3W8/3DaFYOKoMipLk7rBKyIF77CJ38zqgO8Cswie4gXA3Y/JYlw5Zxb02aPO2kSk0GXSt/7PCZpvdgJzCHrs/M9+P5Gn6msqWd+kK34RKWyZJP5yd38EMHff5O7fAD6Q3bCiUVdTya797byxry3qUEREsiaTm7tt4ahb683seoJ+eiqyG1Y0em7wrtvRwviK0oijERHJjkyu+D8LjAA+A5wCfJSgZ82Cc7Cztu2q5xeRwpXJFf8ud99H0J7/41mOJ1ITKksZXV7MOtXzi0gByyTx32pmU4DngT8AT6b21llIzIz6mgp11iYiBe2wVT3u/l7geOBGoAr4vZn1HkS9YNTVVLJuxz7cszbao4hIpDJpx38WcHb4qgJ+R3DlX5DqJ1TwywMdNLe0MWFU2eE/ICKSZzKp6nmcYGD17wL3uXtB92KWOhqXEr+IFKJMWvWMB75JMMbu/Wb2sJl9K7thRSe1szYRkUKUSV89u83sFWAqMAU4AyjOdmBRGV9RwpgRxaxvUuIXkcJ02Cv+MOn/EBhD0HXDjPCG74CZ2d+a2UozW2Fmd5rZsKlTCfrsqVRnbSJSsDKp6jnd3S9y9++6+1Pu3m5m0wdaoJlNJngYrNHdG4Ai4IqB7i8b6sPO2tSyR0QKUSaJ/14zG9UzY2azgN8OstwkUG5mSYKngrcOcn9Dqr6mkpbWTnbsVZ89IlJ4Mkn83wF+a2YVZnYK8GuCbhsGxN23AP8MvAZsA/a4+4O9tzOz68xssZktbm5uHmhxA1I3QTd4RaRwZfIA1+8JBlp/ELgNuNzdXxxogWY2BrgUmA4cBYw0s3ecSNx9vrs3untjdXX1QIsbkNTO2kRECk3aVj1mdiOQWsk9GngZuN7MBjPm7vnAq+7eHJZzD0FLoWHTx/+4ilLGV5SwXjd4RaQA9decc3Gv+SVDVOZrwOlmNgI4AJzXR1mRq5tQyVpd8YtIAUqb+HvG2jWzkUCru3eF80XAgDurd/dFZnYXsJRgVK8XgPkD3V+21NdUcPfSLbg7ZhZ1OCIiQyaTm7uPAOUp8+XAw4Mp1N2/7u4z3b3B3a9292HXfKauppJ9bZ1s3dMadSgiIkMqk8RfFvbHD0A4PSJ7IQ0P9eq6QUQKVCaJf7+Zze6ZCZt0HsheSMNDT8se9c0vIoUmk945Pwf82sy2AgZMBD6S1aiGgaoRJVRXlqrrBhEpOJl00va8mc0EZoSL1rp7R3bDGh40GpeIFKJMqnogSPqzgNnAlWb2seyFNHzMnDiKNdtbONDeFXUoIiJDJpPeOb9OMOzijcAc4PvAJVmOa1g4d+YE2jq7eWJdU9ShiIgMmUyu+P+U4CGr7e7+ceDdBE/xFrzTpo9lzIhiFq7YHnUoIiJDJpPEf8Ddu4HOsJfOJoJBWQpesijB+2fV8OjqJto6Vd0jIoUhk8S/2MyqgH8n6LZhKfBMVqMaRuY1TKKlrZM/bngj6lBERIZEJq16/jqc/KmZ3Q+McveXshvW8HHGceOoLE2ycPl2zp1ZE3U4IiKDlkk7fszsQ8BZBL11PgXEJvGXJos47/gJPLR6Bx1d3RQXZdoQSkRkeMqkVc9NwF8Cy4EVwF+Y2Y+zHdhwMrdhErvf6mDRK7uiDkVEZNAyueI/FzjewwFozex2YGVWoxpm3ltfTXlxEQtXbOOsuvFRhyMiMiiZ1FtsAKalzE8Nl8VGeUkRc2ZW88DKHXR1awB2EclvaRO/mf3WzBYAlcBqM3vczB4DVofLYmVuwyTe2NfGkk1vRh2KiMig9FfV8885iyIPnDtzAiXJBAtXbOPU6WOjDkdEZMD6G4HriVwGMtxVlCY5p66a+1ds56sfmEUioVG5RCQ/qW3iEZjXMJFte1pZtnl31KGIiAyYEv8ROP/4GpIJ43713SMieay/m7vzzexyMxvyG7lmVmVmd5nZGjNbbWbvGeoysmH0iGLOOG48C1dsJ2zdKiKSd/q74r+FoCfO+8zsETP7BzN79xCVewNwv7vPDMtYPUT7zbp5DRN5bddbrNq2N+pQREQGJG3id/dF7v4Ndz8b+DDwGvB3ZvaCmd1qZh8eSIFmNho4h+DEgru3u3veVJpfMKuGhKHqHhHJWxnV8bv7Tne/090/5u4nAz8G6gZY5nSgGfh5eBK52cxG9t7IzK4zs8Vmtri5uXmARQ29cRWlnDp9rProF5G8NaCbu+6+xN2/PcAykwRDOP4kPInsB77YRxnz3b3R3Rurq6sHWFR2zGuYxIamfWxo0ni8IpJ/omjVsxnY7O6Lwvm7CE4EeePCd00EYOFyXfWLSP7JeeJ39+3A62Y2I1x0HrAq13EMxsTRZcyeVqXqHhHJS5l0y/xnPU06zewfzeweMxvsFfrfAHeY2UvAScB3Brm/nLvohEms2raXTTv3Rx2KiMgRyeSK/6vu3mJmZwHnE7TG+clgCnX3F8P6+xPd/TJ3z7uezw5W9+iqX0TyTCaJv2eU8Q8A893990BJ9kLKD1PHjuCEyaOV+EUk72SS+LeY2c+AjxA8zFWa4ecK3tyGiSx7fTdbdx+IOhQRkYxlksA/DDwAXBg+aDUW+PusRpUn5jUE1T16mEtE8kkmiX8S8Ht3X29m7wP+DHguq1HliWOqK5hRU6nELyJ5JZPEfzfQZWbHAfMJhl78ZVajyiNzGyby/KZdNLW0Rh2KiEhGMkn83e7eCXwIuNHd/57gV4AA806YiDs8uHJH1KGIiGQkk8TfYWZXAh8DfhcuK85eSPllRk0l08ePVHWPiOSNTBL/x4H3AN9291fNbDrwi+yGlT/MjLkNE3nmlZ28ub896nBERA7rsInf3VcBnweWm1kDQT87/5T1yPLIRQ2T6Op2Hlqt6h4RGf4y6bLhfcB6gq6YbwLWmdk5WY4rrzRMHsWUMeWq7hGRvJBJVc8PgQvc/b3ufg5wIfCj7IaVX8yMue+ayB/WN7O3tSPqcERE+pVJ4i9297U9M+6+Dt3cfYd5J0yko8t5dHVT1KGIiPQrk8S/OBwl633h69+BxdkOLN+cPHUMNaNKWbhiW9ShiIj0K5PE/1cE/eV/JnytCpdJikTCuPBdE3liXTNvtXdGHY6ISFqZtOppc/d/cfcPha8fuXtbLoLLN3MbJtLa0c3ja4fPGMEiIr0l060ws+WAp1vv7idmJaI8dmrtWMaOLGHhiu1cdIIebhaR4Slt4gcuzlkUBSJZlOCCWTX8dtlWWju6KCsuijokEZF36K+q5zV335TuBWBmlqM488bchonsb+/iqfVvRB2KiEif+kv8j5nZ35jZtNSFZlZiZuea2e3ANdkNL/+ccex4RpUlNTKXiAxb/VX1zAU+AdwZ9s+zGygDioAHgX919xcGWrCZFRE0C93i7gVTrVSSTHD+rBoeXr2Djq5uios0WJmIDC9ps5K7t7r7Te5+JnA0cB4w292PdvdPDSbphz4LrB7kPoaleQ2T2HOgg2de3hl1KCIi75DR5ai7d7j7tnDoxUEzsykEg7ffPBT7G27OrhvPyJIiPcwlIsNSVPUQ/wp8AehOt4GZXWdmi81scXNzfrWLLysuYs7MCTy4cgdd3WlbxIqIRCLnid/MLgaa3H1Jf9u5+3x3b3T3xurq6hxFN3TmNUxi5/52nnt1V9ShiIgcIm3iN7MWM9ub5tVsZs+a2XkDKPNM4BIz2wj8F3Cumf3nAOMftt43o5rSZIL7Vd0jIsNMfzd3K919VF8vYCLwF8ANR1qgu3/J3ae4ey1wBfCou390oP+A4WpkaZL31ldz34rtHGjvijocEZGDBlTV4+5d7r4MuHGI4ykonzxrOs0tbdzwyPqoQxEROWhQdfzu/rNBfv7xQmrD39tpx4zjw41TuPkPr7Bm+96owxERAaJr1RMbX5p3PKPKi/nSPcvpVgsfERkGlPizbMzIEr568fG88Npu7njutajDERFR4s+Fy06azJnHjeP7C9fQtLc16nBEJOaU+HPAzPi/l51AW1c3/+d3q6IOR0RiTok/R6aPH8lnzj2O37+0jcfWaEB2EYmOEn8OXXfOsRw3oYJ//J8VGpdXRCKjxJ9DJckE37n8BLbsPsAND6ttv4hEQ4k/x06dPpYr/mQqNz/1Kqu2qm2/iOSeEn8EvjhvJmNGFPOle5er904RyTkl/ghUjSjhqxfPYtnru7lj0aaowxGRmFHij8gl7z6Ks+vG8/3717JDbftFJIeU+CMStO1voKOrm28sWBl1OCISI0r8ETp63Eg+c14dC1ds5+FVO6IOR0RiQok/Yp86+xjqayr4+oKV7G9T234RyT4l/oiltu3/0UProg5HRGJAiX8YaKwdy5+fNo1b//gqK7bsiTocESlwSvzDxD9cOJOxI0v5str2i0iWKfEPE6NHFPO1D87ipc17+MUzG6MOR0QKmBL/MPLBEydxTn01P3hgLdv2HIg6HBEpUEr8w4iZ8e3LGuhyV9t+EcmanCd+M5tqZo+Z2SozW2lmn811DMPZ1LEj+Ox59TywcgcPrtwedTgiUoCiuOLvBP7O3WcBpwOfNrNZEcQxbP3vs6czc2IlX1+wkn1q2y8iQyznid/dt7n70nC6BVgNTM51HMNZcVGCb19+Atv3tvLPD6yNOhwRKTCR1vGbWS1wMrCoj3XXmdliM1vc3Nyc69Aid8rRY7j69KO57emNfPe+1WriKSJDJhlVwWZWAdwNfM7d3zEiibvPB+YDNDY2xjLrffXiWbjDz558hfVN+7jhipOoLCuOOiwRyXORXPGbWTFB0r/D3e+JIoZ8UFyU4FuXNfCtS9/FE+ua+dBNT/PazreiDktE8lwUrXoMuAVY7e7/kuvy89HV76nlF584laaWNi758VM88/LOqEMSkTwWxRX/mcDVwLlm9mL4uiiCOPLKGceN5zefPpNxI0u4+pZF/HLRa1GHJCJ5Kud1/O7+FGC5LrcQ1I4fyb2fPpPP3PkCX753Oet2tPCPHzieZJGewxORzClj5JlRZcXccs2f8Kmzp3Pb0xu59ufPs+etjqjDEpE8osSfh4oSxlc+MIvv/+mJLHp1J5fd9Edebt4XdVgikieU+PPYhxun8stPnc7eAx1c9uM/8sS6+D3vICJHTok/z/1J7Vh+c/2ZTK4q5+M/f45bn3oV91g+9iAiGVLiLwBTxozg7r86g/OPr+Gbv1vFl+5ZTntnd9RhicgwpcRfIEaWJvnpR0/h+jnH8V/Pv85Hb1nErv3tUYclIsOQEn8BSSSMz184gxuuOIllr+/mkn97ijXb39EbhojEnBJ/Abr0pMn891+8h/bObj5441P87a9eZNnru6MOS0SGCcuHG4GNjY2+ePHiqMPIO017W7np8Ze5a8lm9rV1cvK0Kq49o5Z5DZMoSeqcL1LozGyJuze+Y7kSf+Frae3g7iWbuf2ZTbz6xn4mVJZy1WlH8+enTaO6sjTq8EQkS5T4he5u54n1zdz2x408sa6ZkqIEF584iWvPrOXEKVVRhyciQyxd4o+sP37JvUTCmDNjAnNmTODl5n384plN/Hrx69zzwhZmT6vi2jOnM69hIsXq+0ekoOmKP+ZaWju4a8lmbn96Ixt3vkXNqKAa6MpTVQ0kku9U1SP96u52nljXzM+f3siTPdVA757EVadN48QpVfoVIJKHVNUj/UokjDkzJzBn5gQ2NO3jP57ZyN1LNnPP0i2UFSc4cXIVJx9dxexpY5g9bYx+DYjkMV3xS1p7Wzt4Ym0zS197k6Wv7WbV1j10dAXfl6ljyw+eBGZPG8PMSZX6VSAyzKiqRwattaOLlVv3sHTT7vBk8CY79rYBBL8KpvT8Iqhi9tFjGF+hXwUiUVLilyHn7mzd08rSTW/2+atg2tgRnDBlNFPGlHPU6HKOqipn0ugyJleVUzWimGD4ZRHJFtXxy5AzMyZXlTO5qpwPvvsoIPhVsGLLnuBEsGk3K7bs4aGVO2jvOrS30LLiBEdV9ZwQypg0OtjPpKqyg8vLS4qi+GeJFLxIEr+ZzQVuAIqAm939e1HEIUOvrLiIxtqxNNaOPbisu9vZub+dbXsOsHX3AbbsbmXb7gNs3XOArbtbeXxtM8372uj943PMiGJqRpUxqryYUWVJKsuKqSxLMip8rywrZlT5oct7tisrTugXhUgaOU/8ZlYE/Bh4P7AZeN7MFrj7qlzHIrmRSBjVlaVUV5amfUK4vbObHXtb2ZpyQti6+wA79rbR0trBlt2ttLS20NLaSUtrB92HqaEsLjIqy4qpKE1SVpygJJmgNFlEaTIRvoooLU6ZTibC+ZRtiosoKUqQLDKKEkYyYSQTCYqKguminvlEynxRsKxnvudlBgmz8BX8WipKBNMJ63u9SLZEccV/KrDB3V8BMLP/Ai4FlPhjrCSZYOrYEUwdO+Kw27o7+9u7aGntoKW1k70HwvfWDvaGJ4ae5fvaOmnv7Kats5u2zi7aOrppae0Mpju7aevopr2rm7aOYL7zcGeUHCpKGAaYgRGcHA6ZJjhBGEDKCSR1ufWsPLgfDk4Ha6zX/DtPOqmzh0zTz3aHLO//JHbYU9wgz4GDPYVGfRL+zuUncOr0sYff8AhEkfgnA6+nzG8GTuu9kZldB1wHMG3atNxEJnnBzKgoTVJRmmTS6KHdd2dXz4ng7ZNFV7fT2e10dnk43X1w2dvv3XR0HTrfs323Q7c77m9Pd3U7Hk73tb479XOAOzjBZ9zD917LoWc/KduG/65gvadMp7ynLD90+7fX8fbHe0+G23uf6w7XduRwp9nBNj4Z9Gl8GFwHjCwd+ntdw/bmrrvPB+ZD0Kon4nAkJpJFCZJFCUaURB2JSPZE8cTNFmBqyvyUcJmIiORAFIn/eaDOzKabWQlwBbAggjhERGIp51U97t5pZtcDDxA057zV3VfmOg4RkbiKpI7f3e8D7ouibBGRuFOvWiIiMaPELyISM0r8IiIxo8QvIhIzedEts5k1A5sG+PHxwBtDGM5QU3yDo/gGR/EN3nCO8Wh3r+69MC8S/2CY2eK++qMeLhTf4Ci+wVF8g5cPMfamqh4RkZhR4hcRiZk4JP75UQdwGIpvcBTf4Ci+wcuHGA9R8HX8IiJyqDhc8YuISAolfhGRmCmYxG9mc81srZltMLMv9rG+1Mx+Fa5fZGa1OYxtqpk9ZmarzGylmX22j23eZ2Z7zOzF8PW1XMUXlr/RzJaHZS/uY72Z2f8Lj99LZjY7h7HNSDkuL5rZXjP7XK9tcnr8zOxWM2sysxUpy8aa2UNmtj58H5Pms9eE26w3s2tyGN8PzGxN+P93r5n1OQDy4b4LWYzvG2a2JeX/8KI0n+33bz2L8f0qJbaNZvZims9m/fgNmodDvuXzi6B755eBY4ASYBkwq9c2fw38NJy+AvhVDuObBMwOpyuBdX3E9z7gdxEew43A+H7WXwQsJBjC9HRgUYT/19sJHkyJ7PgB5wCzgRUpy74PfDGc/iLwT318bizwSvg+Jpwek6P4LgCS4fQ/9RVfJt+FLMb3DeDzGfz/9/u3nq34eq3/IfC1qI7fYF+FcsV/cAB3d28HegZwT3UpcHs4fRdwnuVoFGV33+buS8PpFmA1wdjD+eRS4D888CxQZWaTIojjPOBldx/ok9xDwt2fBHb1Wpz6HbsduKyPj14IPOTuu9z9TeAhYG4u4nP3B929M5x9lmD0u0ikOX6ZyORvfdD6iy/MGx8G7hzqcnOlUBJ/XwO4906sB7cJv/x7gHE5iS5FWMV0MrCoj9XvMbNlZrbQzN6V08CCYaUfNLMl4UD3vWVyjHPhCtL/wUV5/ABq3H1bOL0dqOljm+FyHD9B8AuuL4f7LmTT9WFV1K1pqsqGw/E7G9jh7uvTrI/y+GWkUBJ/XjCzCuBu4HPuvrfX6qUE1RfvBm4E/ifH4Z3l7rOBecCnzeycHJd/WOFQnZcAv+5jddTH7xAe/OYflm2lzewrQCdwR5pNovou/AQ4FjgJ2EZQnTIcXUn/V/vD/m+pUBJ/JgO4H9zGzJLAaGBnTqILyiwmSPp3uPs9vde7+1533xdO3wcUm9n4XMXn7lvC9ybgXoKf1KkyOcbZNg9Y6u47eq+I+viFdvRUf4XvTX1sE+lxNLNrgYuBq8KT0ztk8F3ICnff4e5d7t4N/HuacqM+fkngQ8Cv0m0T1fE7EoWS+DMZwH0B0NOC4k+BR9N98YdaWCd4C7Da3f8lzTYTe+45mNmpBP83OTkxmdlIM6vsmSa4Cbii12YLgI+FrXtOB/akVGvkStorrSiPX4rU79g1wG/62OYB4AIzGxNWZVwQLss6M5sLfAG4xN3fSrNNJqPm5KsAAAObSURBVN+FbMWXes/o8jTlZvK3nk3nA2vcfXNfK6M8fkck6rvLQ/UiaHWyjuCO/1fCZd8k+JIDlBFUEWwAngOOyWFsZxH87H8JeDF8XQT8JfCX4TbXAysJWik8C5yRw/iOCctdFsbQc/xS4zPgx+HxXQ405vj/dyRBIh+dsiyy40dwAtoGdBDUM3+S4J7RI8B64GFgbLhtI3Bzymc/EX4PNwAfz2F8Gwjqx3u+gz2t3I4C7uvvu5Cj+H4RfrdeIkjmk3rHF86/4289F/GFy2/r+c6lbJvz4zfYl7psEBGJmUKp6hERkQwp8YuIxIwSv4hIzCjxi4jEjBK/iEjMKPFLwTGzp9MsLzezJ8ysyMyOMrO7wuUnpesJcoDlV5nZX6fMHyxrgPt7OF1PnyIDoeacEhtm9mmC3ilv6LX8WoLnEq4/gn0l/e0Oz3qvqyXoKbRh4NEesr9rgCnu/u2h2J+Irvil4JjZvjSrriJ8mtbMas1sRfj05zeBj4T9p38kfPryVjN7zsxeMLNLw89ca2YLzOxR4BEzqzCzR8xsadj/ek8vkd8Djg3394OessJ9lJnZz8PtXzCzOSn7vsfM7regn/7vp8S9gOCpZZEhkYw6AJFcCBP8Me6+MXW5u7dbMGjLwSt+M/sOQZcen7BgsJLnzOzh8COzgRPdfVfYb8vl7r437BfoWTNbQNAXf4O7nxTurzalyE8HxfoJZjaToBfH+nDdSQQ9t7YBa83sRnd/3d3ftGAgoXHunutuKKQAKfFLXIwHdme47QXAJWb2+XC+DJgWTj/k7j39tBvwnbD3xW6C7oH76oo51VkEvYfi7mvMbBPQk/gfcfc9AGa2Cjiat7sgbiLoGkCJXwZNiV/i4gBBAs+EAf/L3dcestDsNGB/yqKrgGrgFHfvMLONR1BGX9pSprs49O+zjODfIDJoquOXWPBgtKsiM+srMbcQDInZ4wHgb1J6+zw5zW5HA01h0p9DcIXe1/5S/YHghEFYxTMNWJtmW8LtDJhIMKSfyKAp8UucPEhQ1dLbY8Csnpu7wLeAYuAlM1sZzvflDqDRzJYDHwPWAIT18H8Mbx7/oNdnbgIS4Wd+BVzr7m307xTg2XStiESOlJpzSmyY2Wzgb9396qhjORJmdgOwwN0fiToWKQy64pfY8GDA+8fMrCjqWI7QCiV9GUq64hcRiRld8YuIxIwSv4hIzCjxi4jEjBK/iEjMKPGLiMTM/weLS08gRYtKyAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: O valor de $\\Delta w$ depende da distribuição dos dados utilizados.\n",
        "\n",
        "Valores comumente utilizados tendem a $0$, em uma faixa $10^{-7}$ a $10^{-3}$. \n",
        "\n",
        "Valores muito altos de $\\Delta w$ provocam muitas oscilações durante as iterações, impossibilitando sua convergência.\n",
        "\n",
        "Valores muito baixos de $\\Delta w$ ocasionam lentidão e podem não convergir até o fim das iterações.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) Conforme informado, o custo para executar $(x_i w - y_i)^2$ (J) é $O(N)$. \n",
        "\n",
        "Uma única atualização (um passo de gradiente) demanda a execução da função J duas vezes para cada parâmetro $N$: $$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$\n",
        "\n",
        "Logo, o custo computacional em única atualização (um passo de gradiente) é $O(N^2)$. \n",
        "\n",
        "b) Utilizando o método de backpropagation, são necessárias ao menos duas iterações na rede: forward e backward.   \n",
        "\n",
        "Assim, o  custo computacional em única atualização (um passo de gradiente) é $O(2N)$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta:\n",
        "\n",
        "\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "\n",
        "No começo do treinamento de um classificador que é inicializado aleatoriamente, a probabilidade predita $(p_j)$ é a mesma para todas as classes, ou seja, $(1/K)$. \n",
        "\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log (1/K) $$\n",
        "\n",
        "Como o classificador é one-hot, somente uma das classes terá $y_j$ igual a 1. As demais terão o multiplicador $y_j$ igual a 0. \n",
        "\n",
        "Logo, o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente, com a equação de entropia cruzada disponibilizada é:\n",
        "\n",
        "$$L = - \\log (1/K)$$\n",
        "$$L = - \\log (K^{-1})$$\n",
        "$$L = - (-1)*\\log (K)$$\n",
        "$$L = \\log (K) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}