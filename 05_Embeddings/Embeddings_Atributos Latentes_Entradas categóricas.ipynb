{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "12px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "threshold": 4,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leolellisr/deep_learning_projects/blob/main/05_Embeddings/Embeddings_Atributos%20Latentes_Entradas%20categ%C3%B3ricas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMjtDxIqf_DN"
      },
      "source": [
        "# Embedding - Atributos Latentes - Entradas categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtaOxkUff_DP"
      },
      "source": [
        "Este notebook apresenta o conceito de embedding e como usá-lo no PyTorch, através dos seguintes exemplos numéricos:\n",
        "- Rede com entrada categórica (one-hot) e camada densa linear\n",
        "- Embedding como forma eficiente de tratar entrada categórica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wtCuxRLf_DP"
      },
      "source": [
        "## Importação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.173050",
          "start_time": "2018-09-10T10:48:18.938674"
        },
        "id": "gYkGO3rHf_DQ"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJyfXhkjf_DU"
      },
      "source": [
        "## Entrada categórica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKdtFbaMf_DV"
      },
      "source": [
        "Uma variável categórica pode ter um valor dentro de um conjunto limitado que represente uma categoria nominal.\n",
        "Alguns exemplos de variáveis categóricas:\n",
        "- Grupo sanguíneo: A, B, AB or O.\n",
        "- Cidade onde uma pessoa reside\n",
        "- Cor de um produto: vermelho, verde, azul\n",
        "- Uma palavra, dentro de um vocabulário limitado\n",
        "- Dias da semana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW3BjU2qf_DV"
      },
      "source": [
        "# Rede neural com entrada categórica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC0OBsx6f_DW"
      },
      "source": [
        "Quando a rede neural possui entradas categóricas, temos a necessidade de colocá-lo na forma \n",
        "categórica utilizando a codificação *one-hot*. \n",
        "Iremos fazer um exemplo de rede neural com apenas uma camada densa e entrada com \n",
        "dados categóricos com os seguintes parâmetros:\n",
        "- entrada categórica pertencente a um conjunto de 20 classes (n_classes)\n",
        "- entrada é constituída de 10 amostras categóricos (n_amostras)\n",
        "- cada amostra é um número (id) entre 0 e 19: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]\n",
        "- camada densa linear com 5 neurônios (n_neuronios)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.178715",
          "start_time": "2018-09-10T10:48:19.175011"
        },
        "id": "XxH_8VuLf_DX"
      },
      "source": [
        "n_classes = 20\n",
        "n_neuronios = 5\n",
        "n_amostras = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yokkCP04f_Da"
      },
      "source": [
        "## Diagrama da rede neural com entradas categóricas de uma camada e sem bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrfD6_OYf_Db"
      },
      "source": [
        "<img src='https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_neural.png' width = \"400\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCotY82cf_Dc"
      },
      "source": [
        "### Criação da codificação categórica (one-hot) da sequência de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.193654",
          "start_time": "2018-09-10T10:48:19.180824"
        },
        "id": "3ObtfGAjf_Dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0b9af2-903b-4b13-f5b1-aa8b77933341"
      },
      "source": [
        "x = torch.tensor([19, 10, 0, 1, 7, 5, 0, 1, 15, 2])\n",
        "x, x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([19, 10,  0,  1,  7,  5,  0,  1, 15,  2]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsL2Rf5vf_Dh"
      },
      "source": [
        "Codificação one-hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIcx-wfVhi6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bdc9e9-fc48-4fe7-9f1e-f3a631a83339"
      },
      "source": [
        "x_oh = torch.nn.functional.one_hot(x, n_classes)\n",
        "print(x_oh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u3WvjFvf_Dm"
      },
      "source": [
        "## Criação do modelo da rede densa com 5 camadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.218509",
          "start_time": "2018-09-10T10:48:19.212012"
        },
        "id": "rEMVnMT2f_Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e2471a-0aca-4582-e575-defafd5b6372"
      },
      "source": [
        "linear = nn.Linear(n_classes,n_neuronios,bias=False)\n",
        "linear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=20, out_features=5, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQbxPtBbf_Dr"
      },
      "source": [
        "### Criação dos pesos da rede"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xg0bukf_Dr"
      },
      "source": [
        "Como ilustração, iremos inicializar a rede com pesos de modo que possamos identificar quando cada conjunto de pesos\n",
        "for utilizado para cada símbolo categórico:\n",
        "- quando a categoria for $i$, os neurônios de saída devem receber os valores $[i,2i,3i,4i,5i]$.\n",
        "\n",
        "Os pesos da rede possuem 20 linhas (uma para cada classes de entrada) por 5 colunas (atributos de cada categoria):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.230338",
          "start_time": "2018-09-10T10:48:19.220274"
        },
        "id": "H0lcNo4Xf_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3338d5f-890a-427b-f41e-e7e002456f04"
      },
      "source": [
        "#W = np.arange(1,n_neuronios+1).reshape(-1,1).dot(np.arange(n_classes).reshape(1,-1))\n",
        "W = np.random.rand(n_neuronios,n_classes)\n",
        "\n",
        "my_weights = OrderedDict([\n",
        "    ('weight',  torch.FloatTensor(W.astype(np.float)))])\n",
        "\n",
        "linear.load_state_dict(my_weights) # inicializa pesos da camada linear\n",
        "linear.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[0.6258, 0.7464, 0.6481, 0.5349, 0.8447, 0.2560, 0.9127, 0.8350, 0.0771,\n",
              "                       0.9713, 0.4828, 0.2546, 0.0546, 0.6169, 0.2141, 0.8123, 0.6294, 0.3507,\n",
              "                       0.4231, 0.8096],\n",
              "                      [0.3767, 0.4146, 0.3383, 0.2194, 0.0779, 0.2691, 0.8490, 0.7903, 0.9121,\n",
              "                       0.0042, 0.0761, 0.2240, 0.5342, 0.4134, 0.6475, 0.1445, 0.0171, 0.8878,\n",
              "                       0.3415, 0.8888],\n",
              "                      [0.7951, 0.4082, 0.4228, 0.0600, 0.7944, 0.4078, 0.3504, 0.3307, 0.9140,\n",
              "                       0.0494, 0.9146, 0.5351, 0.9779, 0.6522, 0.6038, 0.8433, 0.8208, 0.3839,\n",
              "                       0.8875, 0.4385],\n",
              "                      [0.3632, 0.3165, 0.5176, 0.4890, 0.3262, 0.1442, 0.5012, 0.2695, 0.0221,\n",
              "                       0.9377, 0.7834, 0.0833, 0.0217, 0.9680, 0.6222, 0.1915, 0.8600, 0.2611,\n",
              "                       0.1009, 0.8831],\n",
              "                      [0.9843, 0.3137, 0.0159, 0.2242, 0.1225, 0.5958, 0.9135, 0.4097, 0.9473,\n",
              "                       0.8941, 0.8460, 0.4550, 0.9323, 0.9150, 0.9404, 0.5281, 0.7531, 0.8078,\n",
              "                       0.5670, 0.1135]]))])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa508Dyqf_Dy"
      },
      "source": [
        "## Predição com as 10 amostras: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWcQpGB2f_Dz"
      },
      "source": [
        "<img src = 'https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_categorical_predict.png' width=\"800\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE-Yhjzqf_Dz"
      },
      "source": [
        "Observe que a predição da rede com a sequência categórica acima é feita com a substituição\n",
        "da categoria com os 5 atributos de cada classe.\n",
        "\n",
        "Observe que data_oh estava em long e foi preciso ser convertido para float para entrar na rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.296052",
          "start_time": "2018-09-10T10:48:19.240730"
        },
        "id": "OaU3fj0if_D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53ae9e2-1cea-4da7-faaa-e6b1d07def4b"
      },
      "source": [
        "y_pred = linear(x_oh.type(torch.float))\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8096, 0.8888, 0.4385, 0.8831, 0.1135],\n",
              "        [0.4828, 0.0761, 0.9146, 0.7834, 0.8460],\n",
              "        [0.6258, 0.3767, 0.7951, 0.3632, 0.9843],\n",
              "        [0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
              "        [0.8350, 0.7903, 0.3307, 0.2695, 0.4097],\n",
              "        [0.2560, 0.2691, 0.4078, 0.1442, 0.5958],\n",
              "        [0.6258, 0.3767, 0.7951, 0.3632, 0.9843],\n",
              "        [0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
              "        [0.8123, 0.1445, 0.8433, 0.1915, 0.5281],\n",
              "        [0.6481, 0.3383, 0.4228, 0.5176, 0.0159]], grad_fn=<MmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7OqvdJf_D4"
      },
      "source": [
        "# Embedding como implementação eficiente de entradas categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK_1SXx9f_D5"
      },
      "source": [
        "Nesta implementação de rede neural com entrada categórica, existem dois fatores que dificultam a sua\n",
        "implementação eficiente:\n",
        "- necessidade de se fazer a codificação para categórico antes de colocá-lo na rede\n",
        "- se o número de classes for muito alto, a implementação pode se tornar muito ineficiente. É comum\n",
        "  termos centenas de milhares de classes, como é o caso de palavras dentro de um vocabulário.\n",
        "  \n",
        "A camada `Embedding` resolve estes dois problemas de forma eficiente:\n",
        "- faz a codificação categórica automaticamente e já retorna a aplicação dos pesos nos valores categóricos\n",
        "\n",
        "Assim, a camada `Embedding` é sempre uma camada de entrada e nela é preciso especificar o número de\n",
        "classes e o número de atributos de cada classe:\n",
        "\n",
        "O diagrama a seguir mostra a aplicação do Embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66swAUsef_D5"
      },
      "source": [
        "<img src = 'https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_1.png' width=\"700pt\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cf0xQkRf_D6"
      },
      "source": [
        "## Criação da mesma rede, porém agora mais eficiente, com o uso do Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.302901",
          "start_time": "2018-09-10T10:48:19.297703"
        },
        "id": "UV2-vyyZf_D6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85a8a91-cef7-4cad-974a-3326090e5375"
      },
      "source": [
        "emb = nn.Embedding(n_classes, n_neuronios)\n",
        "emb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(20, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.312290",
          "start_time": "2018-09-10T10:48:19.304445"
        },
        "id": "Q-U-QgL2f_D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952b60e6-57cb-4ae8-c045-0c735db89d12"
      },
      "source": [
        "my_weights = OrderedDict([\n",
        "    ('weight',  torch.FloatTensor(W.T.astype(np.float)))])\n",
        "emb.load_state_dict(my_weights) # inicializa pesos da camada linear\n",
        "emb.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([[0.6258, 0.3767, 0.7951, 0.3632, 0.9843],\n",
              "                      [0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
              "                      [0.6481, 0.3383, 0.4228, 0.5176, 0.0159],\n",
              "                      [0.5349, 0.2194, 0.0600, 0.4890, 0.2242],\n",
              "                      [0.8447, 0.0779, 0.7944, 0.3262, 0.1225],\n",
              "                      [0.2560, 0.2691, 0.4078, 0.1442, 0.5958],\n",
              "                      [0.9127, 0.8490, 0.3504, 0.5012, 0.9135],\n",
              "                      [0.8350, 0.7903, 0.3307, 0.2695, 0.4097],\n",
              "                      [0.0771, 0.9121, 0.9140, 0.0221, 0.9473],\n",
              "                      [0.9713, 0.0042, 0.0494, 0.9377, 0.8941],\n",
              "                      [0.4828, 0.0761, 0.9146, 0.7834, 0.8460],\n",
              "                      [0.2546, 0.2240, 0.5351, 0.0833, 0.4550],\n",
              "                      [0.0546, 0.5342, 0.9779, 0.0217, 0.9323],\n",
              "                      [0.6169, 0.4134, 0.6522, 0.9680, 0.9150],\n",
              "                      [0.2141, 0.6475, 0.6038, 0.6222, 0.9404],\n",
              "                      [0.8123, 0.1445, 0.8433, 0.1915, 0.5281],\n",
              "                      [0.6294, 0.0171, 0.8208, 0.8600, 0.7531],\n",
              "                      [0.3507, 0.8878, 0.3839, 0.2611, 0.8078],\n",
              "                      [0.4231, 0.3415, 0.8875, 0.1009, 0.5670],\n",
              "                      [0.8096, 0.8888, 0.4385, 0.8831, 0.1135]]))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H42xISyf_EA"
      },
      "source": [
        "## Predição com mesma sequência: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rb_cwtAf_EB"
      },
      "source": [
        "Confirmamos aqui que a camada Embedding é equivalente à rede densa da entrada categórica feita anteriormente.\n",
        "\n",
        "Observe que não foi necessário criar a codificação one_hot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-09-10T10:48:19.385925",
          "start_time": "2018-09-10T10:48:19.313998"
        },
        "id": "zF8DCcy_f_EB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5c0430-03e5-4f4c-b5b5-12d1007c50df"
      },
      "source": [
        "y = emb(x)  # predição da rede\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8096, 0.8888, 0.4385, 0.8831, 0.1135],\n",
              "        [0.4828, 0.0761, 0.9146, 0.7834, 0.8460],\n",
              "        [0.6258, 0.3767, 0.7951, 0.3632, 0.9843],\n",
              "        [0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
              "        [0.8350, 0.7903, 0.3307, 0.2695, 0.4097],\n",
              "        [0.2560, 0.2691, 0.4078, 0.1442, 0.5958],\n",
              "        [0.6258, 0.3767, 0.7951, 0.3632, 0.9843],\n",
              "        [0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
              "        [0.8123, 0.1445, 0.8433, 0.1915, 0.5281],\n",
              "        [0.6481, 0.3383, 0.4228, 0.5176, 0.0159]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPECr-XOrxRm"
      },
      "source": [
        "## Tratando o embeddings no batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRyYgDOitS8K"
      },
      "source": [
        "No exemplo a seguir, temos dois exemplos num minibatch, cada exemplo com 4 atributos. O shape da entrada x é (2,4)\n",
        "\n",
        "Observe que na saída da camada de embedding é acrescentada uma nova dimensão. O shape da saíde é (2, 4, 5). Cada atributo categórico foi substituído por um vetor com 5 elementos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7LgKP5Zr3Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d6acb5-9f4a-4964-890f-f0c123a44865"
      },
      "source": [
        "x = torch.LongTensor([[1,6,3,2],\n",
        "                      [3,5,9,4]])\n",
        "y = emb(x)\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 5])\n",
            "tensor([[[0.7464, 0.4146, 0.4082, 0.3165, 0.3137],\n",
            "         [0.9127, 0.8490, 0.3504, 0.5012, 0.9135],\n",
            "         [0.5349, 0.2194, 0.0600, 0.4890, 0.2242],\n",
            "         [0.6481, 0.3383, 0.4228, 0.5176, 0.0159]],\n",
            "\n",
            "        [[0.5349, 0.2194, 0.0600, 0.4890, 0.2242],\n",
            "         [0.2560, 0.2691, 0.4078, 0.1442, 0.5958],\n",
            "         [0.9713, 0.0042, 0.0494, 0.9377, 0.8941],\n",
            "         [0.8447, 0.0779, 0.7944, 0.3262, 0.1225]]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqHcUIRpt6CD"
      },
      "source": [
        "Se for necessário fazer uma concatenação dos embeddings categóricos, basta fazer um reshape combinando as duas últimas dimensões:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mddfxs_atJrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc80902-27d7-427e-a6cb-70d207e7624d"
      },
      "source": [
        "print(y.reshape(2,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7464, 0.4146, 0.4082, 0.3165, 0.3137, 0.9127, 0.8490, 0.3504, 0.5012,\n",
            "         0.9135, 0.5349, 0.2194, 0.0600, 0.4890, 0.2242, 0.6481, 0.3383, 0.4228,\n",
            "         0.5176, 0.0159],\n",
            "        [0.5349, 0.2194, 0.0600, 0.4890, 0.2242, 0.2560, 0.2691, 0.4078, 0.1442,\n",
            "         0.5958, 0.9713, 0.0042, 0.0494, 0.9377, 0.8941, 0.8447, 0.0779, 0.7944,\n",
            "         0.3262, 0.1225]], grad_fn=<ViewBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d85vMCtX11V1"
      },
      "source": [
        "## EmbeddingBag\n",
        "\n",
        "O EmbeddingBag permite tratar batchs com diferentes tamanhos de atributos para cada exemplo utilizando uma estrutura de valores e índices. Adicionalmente o\n",
        "EmbeddingBag permite fazer operações de soma, média ou máximo entre os embeddings.\n",
        "\n",
        "No exemplo a seguir temos um EmbeddingBag no modo soma, com 5 classes com dimensão 20 de embedding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE-OwicJqpSI",
        "outputId": "fd07a96f-075b-45f0-e228-f14cd83155b4"
      },
      "source": [
        "embedding_sum = nn.EmbeddingBag(20, 5, mode='sum')\n",
        "embedding_sum.load_state_dict(my_weights)\n",
        "embedding_sum.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
              "                      [ 1.,  2.,  3.,  4.,  5.],\n",
              "                      [ 2.,  4.,  6.,  8., 10.],\n",
              "                      [ 3.,  6.,  9., 12., 15.],\n",
              "                      [ 4.,  8., 12., 16., 20.],\n",
              "                      [ 5., 10., 15., 20., 25.],\n",
              "                      [ 6., 12., 18., 24., 30.],\n",
              "                      [ 7., 14., 21., 28., 35.],\n",
              "                      [ 8., 16., 24., 32., 40.],\n",
              "                      [ 9., 18., 27., 36., 45.],\n",
              "                      [10., 20., 30., 40., 50.],\n",
              "                      [11., 22., 33., 44., 55.],\n",
              "                      [12., 24., 36., 48., 60.],\n",
              "                      [13., 26., 39., 52., 65.],\n",
              "                      [14., 28., 42., 56., 70.],\n",
              "                      [15., 30., 45., 60., 75.],\n",
              "                      [16., 32., 48., 64., 80.],\n",
              "                      [17., 34., 51., 68., 85.],\n",
              "                      [18., 36., 54., 72., 90.],\n",
              "                      [19., 38., 57., 76., 95.]]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxsAALaqvpj8"
      },
      "source": [
        "No batch temos 3 exemplos, sendo o primeiro com 2 valores [0,1], o segundo sendo [2] e o terceiro sendo [4,3] indicados pelos índices [0,2,3].\n",
        "\n",
        "O resultado são 3 embeddings, o primeiro dado pela soma dos embeddings das classes 0 e 1, o segundo pelo embedding da classe 2 e o terceiro pela soma dos embeddings das classes 4 e 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1pYrixWsIjr",
        "outputId": "11287273-5ea0-4d83-9553-9d30fb9c8cf0"
      },
      "source": [
        "input = torch.LongTensor([0,1,2,4,3])\n",
        "offsets = torch.LongTensor([0,2,3])\n",
        "embedding_sum(input, offsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
              "        [ 2.,  4.,  6.,  8., 10.],\n",
              "        [ 7., 14., 21., 28., 35.]], grad_fn=<EmbeddingBagBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab2Z8VOCf_EE"
      },
      "source": [
        "## Embedding como atributos latentes de um objeto categórico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bEkmSQUf_EF"
      },
      "source": [
        "Podemos interpretar o embedding como uma codificação de atributos latentes de um objeto\n",
        "categórico. Por exemplo, se estamos codificando filmes, as 5 categorias visto no exemplo\n",
        "acima poderiam representar a quantidade de suspense, romantismo, aventura, infantil e terror\n",
        "que um filme possui. Se fosse processar palavras, os atributos poderiam representar o seu\n",
        "significado (*word embedding*).\n",
        "\n",
        "O embedding pode ser fixo (não deve ser treinado), quando sabemos exatamente os atributos\n",
        "das classes ou treináveis, quando queremos que a rede utilize estes atributos como parâmetros\n",
        "a serem minimizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mhm4FBZgzLi"
      },
      "source": [
        "# Usando torch.nn.Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE1w68bIgD3A"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWaPHH_UtHd9"
      },
      "source": [
        "vocab_size = 10\n",
        "dim = 4\n",
        "weight = torch.arange(vocab_size * dim).reshape((vocab_size, dim)).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUjTbS-Chnrx",
        "outputId": "975eab81-3aec-4f51-8f7e-634b48062b99"
      },
      "source": [
        "embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=dim, _weight=weight)\n",
        "embedding_layer.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23.],\n",
              "        [24., 25., 26., 27.],\n",
              "        [28., 29., 30., 31.],\n",
              "        [32., 33., 34., 35.],\n",
              "        [36., 37., 38., 39.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DGDLu3rs08C"
      },
      "source": [
        "token_ids = torch.LongTensor([[4, 1, 9], [0, 1, 2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n46qJpMbiZD8",
        "outputId": "09ede7fb-fae9-4137-9149-c8bf7ef552e0"
      },
      "source": [
        "embeddings = embedding_layer(token_ids)\n",
        "print(f'embeddings.shape: {embeddings.shape}')\n",
        "sum_embeddings = embeddings.sum(1)\n",
        "print(f'sum_embeddings.shape: {sum_embeddings.shape}')\n",
        "print(f'sum_embeddings: {sum_embeddings}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.shape: torch.Size([2, 3, 4])\n",
            "sum_embeddings.shape: torch.Size([2, 4])\n",
            "sum_embeddings: tensor([[56., 59., 62., 65.],\n",
            "        [12., 15., 18., 21.]], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI7RfBWKgETX"
      },
      "source": [
        "# Usando torch.nn.Linear\n",
        "\n",
        "O torch.nn.Embedding é uma forma eficiente de se acessar os embeddings de uma matriz de embeddings. Entretanto, conseguimos o mesmo resultado usando a uma camada linear cujos pesos são os mesmos da matriz de embeddings. Assim está celula serve para ilustrar que embeddings não mais são que uma camada da rede neural sem bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyh606r0gJRg",
        "outputId": "f2d44ef0-afe8-47e2-913b-2cc563f9fb45"
      },
      "source": [
        "linear_layer = torch.nn.Linear(vocab_size, dim, bias=False)\n",
        "linear_layer.weight = torch.nn.Parameter(weight.T)\n",
        "linear_layer.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.,  4.,  8., 12., 16., 20., 24., 28., 32., 36.],\n",
              "        [ 1.,  5.,  9., 13., 17., 21., 25., 29., 33., 37.],\n",
              "        [ 2.,  6., 10., 14., 18., 22., 26., 30., 34., 38.],\n",
              "        [ 3.,  7., 11., 15., 19., 23., 27., 31., 35., 39.]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7Zd3wEgTPL",
        "outputId": "feae0c98-2099-4ba7-aad5-593e401caa9d"
      },
      "source": [
        "bow = torch.zeros(len(token_ids), vocab_size)\n",
        "bow = bow.scatter_(dim=1, index=token_ids, src=torch.ones_like(token_ids).float(), reduce='add')\n",
        "print(f'bow: {bow}')\n",
        "sum_embeddings = linear_layer(bow)\n",
        "print(f'sum_embeddings.shape: {sum_embeddings.shape}')\n",
        "print(f'sum_embeddings: {sum_embeddings}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bow: tensor([[0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "sum_embeddings.shape: torch.Size([2, 4])\n",
            "sum_embeddings: tensor([[56., 59., 62., 65.],\n",
            "        [12., 15., 18., 21.]], grad_fn=<MmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_YWfjFpf_EF"
      },
      "source": [
        "# Aprendizados com este notebook"
      ]
    }
  ]
}